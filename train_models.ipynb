{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3068b3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for installing the packages for the 1st time use !pip install [package name]\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pickle\n",
    "import scipy.sparse as sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7228c994",
   "metadata": {},
   "source": [
    "#  Choose model to train\n",
    "choose between svc (support vector classifier), rfc (random forest classifier), nb (naive bayes), and lr (logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb05ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'lr'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d806288",
   "metadata": {},
   "source": [
    "# Load feature matrices and labels (used to train the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2773e9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT140_DATA_DIR = 'Sentiment140.data' # sentiment 140 data set saved here\n",
    "DG_DATA_DIR = 'D_G data' # D&G data set saved here\n",
    "OUTPUT_DIR = 'output' # intermediate output and models saved here\n",
    "FIGURES_DIR = 'figures' # figures saved here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23402241",
   "metadata": {
    "id": "23402241"
   },
   "outputs": [],
   "source": [
    "word_counts_train = sparse.load_npz(os.path.join(OUTPUT_DIR, 'word_counts_train.npz'))\n",
    "word_counts_test = sparse.load_npz(os.path.join(OUTPUT_DIR, 'word_counts_test.npz'))\n",
    "word_counts_chopsticks = sparse.load_npz(os.path.join(OUTPUT_DIR, 'word_counts_chopsticks.npz'))\n",
    "word_counts_all = sparse.load_npz(os.path.join(OUTPUT_DIR, 'word_counts_all.npz'))\n",
    "\n",
    "X_140 = sparse.load_npz(os.path.join(OUTPUT_DIR, 'X_140.npz'))\n",
    "X_test = sparse.load_npz(os.path.join(OUTPUT_DIR, 'X_test.npz'))\n",
    "X_chopsticks = sparse.load_npz(os.path.join(OUTPUT_DIR, 'X_chopsticks.npz'))\n",
    "X_all = sparse.load_npz(os.path.join(OUTPUT_DIR, 'X_all.npz'))\n",
    "\n",
    "X_train = sparse.load_npz(os.path.join(OUTPUT_DIR, 'X_train.npz'))\n",
    "X_validation = sparse.load_npz(os.path.join(OUTPUT_DIR, 'X_validation.npz'))\n",
    "\n",
    "y_train = np.load(os.path.join(OUTPUT_DIR, 'y_train.npy'), allow_pickle=True)\n",
    "y_trainsmall = np.load(os.path.join(OUTPUT_DIR, 'y_trainsmall.npy'), allow_pickle=True)\n",
    "y_validation = np.load(os.path.join(OUTPUT_DIR, 'y_validation.npy'), allow_pickle=True)\n",
    "y_test = np.load(os.path.join(OUTPUT_DIR, 'y_test.npy'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967acf81",
   "metadata": {
    "id": "8103d147"
   },
   "source": [
    "# Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77199f16",
   "metadata": {
    "id": "77199f16"
   },
   "outputs": [],
   "source": [
    "# fit model with tuned parameters\n",
    "if model_name == 'svc':\n",
    "    model = SVC(kernel='linear', C=0.1, probability=True)\n",
    "elif model_name == 'rfc':\n",
    "    model = RandomForestClassifier(min_samples_split=90)\n",
    "elif model_name == 'nb':\n",
    "    model = MultinomialNB() # using default hyperparameters\n",
    "elif model_name == 'lr':\n",
    "    model = LogisticRegression() # using default hyperparameters\n",
    "else:\n",
    "    raise Exception('unknown model')\n",
    "    \n",
    "    \n",
    "model.fit(X_train, y_trainsmall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb9725b",
   "metadata": {
    "id": "8eb9725b"
   },
   "outputs": [],
   "source": [
    "# prediction on training\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_proba = model.predict_proba(X_train)\n",
    "\n",
    "# prediction on validation\n",
    "y_validation_pred = model.predict(X_validation)\n",
    "y_validation_proba = model.predict_proba(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faccee81",
   "metadata": {
    "id": "faccee81"
   },
   "outputs": [],
   "source": [
    "print('Training performance')\n",
    "print(classification_report(y_trainsmall, y_train_pred))\n",
    "print()\n",
    "print('====================')\n",
    "print()\n",
    "print('Validation performance')\n",
    "print(classification_report(y_validation, y_validation_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bcc42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(y_train_proba[:,1])\n",
    "plt.xlabel('Predicted probability')\n",
    "plt.ylabel('Number of tweets')\n",
    "plt.title('Predicted probability distribution training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6e1e8c",
   "metadata": {
    "id": "2b6e1e8c"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(y_validation_proba[:,1])\n",
    "plt.xlabel('Predicted probability')\n",
    "plt.ylabel('Number of tweets')\n",
    "plt.title('Predicted probability distribution validation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd87895e",
   "metadata": {
    "id": "fd87895e"
   },
   "outputs": [],
   "source": [
    "# prediction on testing (once hyperparameters are tuned)\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_proba = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43018b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(y_test_proba[:,1])\n",
    "plt.xlabel('Predicted probability')\n",
    "plt.ylabel('Number of tweets')\n",
    "plt.title('Predicted probability distribution test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22446019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose positive and negative thresholds\n",
    "topacc = 0 # maximum accuracy\n",
    "top_a = 0 # negative threshold\n",
    "top_b = 0 # positive threshold\n",
    "\n",
    "for i in range(100):\n",
    "    a = 0 + (i*0.01)\n",
    "    for j in range(100):\n",
    "        b = 1 - (j*0.01)\n",
    "        \n",
    "        y_test_pred_binary = []\n",
    "        for k in range(len(y_test_proba)):\n",
    "            if (y_test_proba[k,1]) < a:\n",
    "                y_test_pred_binary.append(0)\n",
    "            elif(y_test_proba[k,1]) > b:\n",
    "                y_test_pred_binary.append(4)\n",
    "            else:\n",
    "                y_test_pred_binary.append(2)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "        #print(a, b, accuracy)\n",
    "        if accuracy > topacc:\n",
    "            topacc = accuracy\n",
    "            top_a = a\n",
    "            top_b = b\n",
    "            y_test_pred = y_test_pred_binary\n",
    "            print(\"acc = \" + str(accuracy) + \" a = \" + str(a) + \" b = \" + str(b))\n",
    "            \n",
    "        \n",
    "print(\"overall top acc = \" + str(topacc)+ \" a = \" + str(top_a)+\" b = \" + str(top_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3067074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Testing performance')\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7a3af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on chopsticks\n",
    "y_chopsticks_proba = model.predict_proba(X_chopsticks)\n",
    "y_chopsticks_pred = [-1 if x < top_a else 1 if x > top_b else 0 for x in y_chopsticks_proba[:,1]] # use thresholds to assign negative (-1), neutral (0), or positive (1) sentiment\n",
    "\n",
    "# prediction on d&g overall\n",
    "y_all_proba = model.predict_proba(X_all)\n",
    "y_all_pred = [-1 if x < top_a else 1 if x > top_b else 0 for x in y_all_proba[:,1]] # use thresholds to assign negative (-1), neutral (0), or positive (1) sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a70036c",
   "metadata": {
    "id": "0a70036c"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(y_chopsticks_proba[:,1])\n",
    "plt.xlabel('Predicted probability')\n",
    "plt.ylabel('Number of tweets')\n",
    "plt.title('Predicted probability distribution D & G chopsticks')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcb470e",
   "metadata": {
    "id": "afcb470e"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(y_all_proba[:,1])\n",
    "plt.xlabel('Predicted probability')\n",
    "plt.ylabel('Number of tweets')\n",
    "plt.title('Predicted probability distribution D & G all')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded555ce",
   "metadata": {
    "id": "ded555ce"
   },
   "source": [
    "# Save model and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbeedd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "with open(os.path.join(OUTPUT_DIR, f'{model_name}_model'), 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# save sentiment 140 predictions\n",
    "np.save(os.path.join(OUTPUT_DIR, f'{model_name}_y_train_pred.npy'), y_train_pred)\n",
    "np.save(os.path.join(OUTPUT_DIR, f'{model_name}_y_train_proba.npy'), y_train_proba)\n",
    "np.save(os.path.join(OUTPUT_DIR, f'{model_name}_y_validation_pred.npy'), y_validation_pred)\n",
    "np.save(os.path.join(OUTPUT_DIR, f'{model_name}_y_validation_proba.npy'), y_validation_proba)\n",
    "\n",
    "np.save(os.path.join(OUTPUT_DIR, f'{model_name}_y_test_pred.npy'), y_test_pred)\n",
    "np.save(os.path.join(OUTPUT_DIR, f'{model_name}_y_test_proba.npy'), y_test_proba)\n",
    "\n",
    "# save D&G predictions\n",
    "np.save(os.path.join(OUTPUT_DIR, f'{model_name}_y_chopsticks_pred.npy'), y_chopsticks_pred)\n",
    "np.save(os.path.join(OUTPUT_DIR, f'{model_name}_y_chopsticks_proba.npy'), y_chopsticks_proba)\n",
    "np.save(os.path.join(OUTPUT_DIR, f'{model_name}_y_all_pred.npy'), y_all_pred)\n",
    "np.save(os.path.join(OUTPUT_DIR, f'{model_name}_y_all_proba.npy'), y_all_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b4d84f",
   "metadata": {
    "id": "18b4d84f"
   },
   "outputs": [],
   "source": [
    "model = pickle.load(open(os.path.join(OUTPUT_DIR, f'{model_name}_model'), 'rb'))\n",
    "\n",
    "y_train_pred = np.load(os.path.join(OUTPUT_DIR, f'{model_name}_y_train_pred.npy'), allow_pickle=True)\n",
    "y_train_proba = np.load(os.path.join(OUTPUT_DIR, f'{model_name}_y_train_proba.npy'), allow_pickle=True)\n",
    "y_validation_pred = np.load(os.path.join(OUTPUT_DIR, f'{model_name}_y_validation_pred.npy'), allow_pickle=True)\n",
    "y_validation_proba = np.load(os.path.join(OUTPUT_DIR, f'{model_name}_y_validation_proba.npy'), allow_pickle=True)\n",
    "\n",
    "y_test_proba = np.load(os.path.join(OUTPUT_DIR, f'{model_name}_y_validation_pred.npy'), allow_pickle=True)\n",
    "y_test_pred = np.load(os.path.join(OUTPUT_DIR, f'{model_name}_y_validation_pred.npy'), allow_pickle=True)\n",
    "\n",
    "y_chopsticks_pred = np.load(os.path.join(OUTPUT_DIR, f'{model_name}_y_chopsticks_pred.npy'), allow_pickle=True)\n",
    "y_chopsticks_proba = np.load(os.path.join(OUTPUT_DIR, f'{model_name}_y_chopsticks_proba.npy'), allow_pickle=True)\n",
    "\n",
    "y_all_pred = np.load(os.path.join(OUTPUT_DIR, f'{model_name}_y_all_pred.npy'), allow_pickle=True)\n",
    "y_all_proba = np.load(os.path.join(OUTPUT_DIR, f'{model_name}_y_all_proba.npy'), allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2353fbac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cUBpuJRd9nxl",
    "outputId": "dc135e99-98b7-43c1-a57d-3765b3be65b3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ko4yARRtH_M",
    "outputId": "f3c9f645-72b3-483a-c9c8-f1cb9d55fa9f"
   },
   "outputs": [],
   "source": [
    "#for installing the packages for the 1st time use !pip install [package name]\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spacy\n",
    "import re\n",
    "from html import unescape\n",
    "\n",
    "!pip install emoji\n",
    "from emoji import UNICODE_EMOJI\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer \n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/content/drive/MyDrive/SF data science research program/Research Project'\n",
    "working_dir = '/content/drive/MyDrive/SF data science research program/florence d&g saved things'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "a00_cLwH2WoC",
    "outputId": "146917d7-9593-40db-8396-053af4c945b3"
   },
   "outputs": [],
   "source": [
    "# load in all data sets\n",
    "\n",
    "# sentiment 140 data\n",
    "sentiment140_train = pd.read_csv(os.path.join(data_dir, 'Sentiment140.data', 'training.1600000.processed.noemoticon.csv'), encoding = \"latin-1\", names=[\"label\", \"id\", \"timestamp\", \"query\", \"user\", \"text\"])\n",
    "sentiment140_train = sentiment140_train.sample(10000) # testing\n",
    "\n",
    "sentiment140_test = pd.read_csv(os.path.join(data_dir, 'Sentiment140.data', 'testdata.manual.2009.06.14.csv'), encoding = \"latin-1\", names=[\"label\", \"id\", \"timestamp\", \"query\", \"user\", \"text\"])\n",
    "\n",
    "\n",
    "# D&G data\n",
    "dg_chopsticks = pd.read_csv(os.path.join(data_dir, 'D&G data', \"dolcegabbana_chopsticks_mentions_daily_expanded.csv\"))\n",
    "dg_general = pd.read_csv(os.path.join(data_dir, 'D&G data', \"dolcegabbana_mentions_daily_all.csv\"), lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4c3b88uvDSF"
   },
   "source": [
    "### Data Preprosessing: \n",
    "##### https://towardsdatascience.com/text-preprocessing-steps-and-universal-pipeline-94233cb6725a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2EL18MswlaD"
   },
   "outputs": [],
   "source": [
    "# load NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73er0sebxg9E"
   },
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XrnWODwt5AF4"
   },
   "outputs": [],
   "source": [
    "# helper function for pre-processing/cleaning a tweet\n",
    "def preprocessor(tweet):\n",
    "    tweet = re.sub (r'@[A-Za-z0-9_]+', '_AT_USER_', tweet) # replace @X with _AT_USER_\n",
    "    tweet = re.sub (r'#[A-Za-z0-9_]+', '_HASHTAG_', tweet) # replace #X with _HASTHAG_\n",
    "    tweet = re.sub (r'^RT[\\s]+', '', tweet) # remove RT (retweet) at the start of the tweet\n",
    "    tweet = unescape(tweet) # unescape the HTML\n",
    "    tweet = tweet.lower() # make everything lowercase\n",
    "    return tweet\n",
    "\n",
    "# helper function for tokenization of a tweet\n",
    "def tokenizer(tweet):\n",
    "    tokens = nlp(tweet) # this processes the tweet text  \n",
    "    # only keep tokens (lemmatized) that are alphanumeric (including \"-\" and \"_\") and not a stop word, or represent an emoji\n",
    "    tokens = [t.lemma_ for t in tokens if (re.match(\"^[a-zA-Z0-9_-]*$\", t.text) and not t.is_stop and len(t.text) > 2) or t.text in UNICODE_EMOJI]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XhHdDGKUQeI"
   },
   "source": [
    "### Creating a Count Vectorizer  (Assigning Value to text for modelling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i6sNuKXlEo-P"
   },
   "outputs": [],
   "source": [
    "corpus = list(df['text']) #the list of sample tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zHWzXVTfEqqI",
    "outputId": "f356b8a6-373e-4566-f0fc-c66aaa73340b"
   },
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNrgyxeEbp6Q"
   },
   "outputs": [],
   "source": [
    "# use the count vectorizer to get a document-word matrix (counts of tokens in each tweet) basically assigning value to words per tweet\n",
    "# pass in through the preprocessor (tweet cleaner) and tokenizer (seperating tweet into individual words)\n",
    "# max_features basically the number of features selected at random and without replacement at split\n",
    "model = CountVectorizer(preprocessor=preprocessor, tokenizer=tokenizer, max_features=2098)\n",
    "word_counts = model.fit_transform(corpus)\n",
    "tokens = model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2SfqSTTFCrw"
   },
   "outputs": [],
   "source": [
    "word_counts # this is a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tfontiu9BWVa"
   },
   "outputs": [],
   "source": [
    "word_counts.toarray() # converts it to dense matrix form (takes up a lot of space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FufvUFKxE-ke"
   },
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xELG84GYh5Mu"
   },
   "source": [
    "### Creating TF-IDF transformer\n",
    "Read more here:  \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer  \n",
    "and here:  \n",
    "https://towardsdatascience.com/tf-idf-explained-and-python-sklearn-implementation-b020c5e83275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qg1X9ahmdwT9"
   },
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "#tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True) \n",
    "X = tfidf_transformer.fit_transform(word_counts) # we use the TF-IDF counts as the feature matrix into our models\n",
    "y = list(df['label']) # labels for supervised model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QeEH-A9qGTwa"
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ezDwvrjWGVNp"
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNKLrpi0Yllc"
   },
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.10, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PGTrau6xw2m"
   },
   "source": [
    "###Training the Machine Learning Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Smgzo16P4CTd"
   },
   "outputs": [],
   "source": [
    "# Spot Check Algorithms\n",
    "models = []\n",
    "\n",
    "# logistic regression\n",
    "models.append(('LR', LogisticRegression()))\n",
    "\n",
    "# naive Bayes model\n",
    "models.append(('NB', MultinomialNB()))\n",
    "\n",
    "# evaluate each model in turn using cross validation\n",
    "results = []\n",
    "names = []\n",
    "print('model: cross-validation accuracy (cross-validation standard deviation)')\n",
    "for name, model in models:\n",
    "\tkfold = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\tcv_results = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LIfK7DGpIdAt"
   },
   "outputs": [],
   "source": [
    "# alternatively, you can train on the train set and set on the test set (see below for testing)\n",
    "penalities = ['l1', 'l2']\n",
    "\n",
    "for penality in penalities:\n",
    "  NB = MultinomialNB()\n",
    "  NB.fit(X_train, y_train)\n",
    "  NB.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQMzPjoxjomd"
   },
   "outputs": [],
   "source": [
    "for penality in penalities:\n",
    "  LR = LogisticRegression()\n",
    "  LR.fit(X_train, y_train)\n",
    "  LR.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNU0zAFUyBkD"
   },
   "source": [
    "###Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VtXKQ_YIiCC"
   },
   "outputs": [],
   "source": [
    "y_pred = NB.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z7Nb7LOVuE8C"
   },
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_validation, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_validation, y_pred, pos_label=4)\n",
    "print('Precision: %f' % precision)\n",
    "\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_validation, y_pred, pos_label=4)\n",
    "print('Recall: %f' % recall)\n",
    "\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_validation, y_pred, pos_label=4)\n",
    "print('F1 score: %f' % f1)\n",
    "\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_validation, y_pred)\n",
    "print('ROC AUC: %f' % auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ryiccu-j568"
   },
   "outputs": [],
   "source": [
    "y__pred = LR.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83WImGqPkHO5"
   },
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_validation, y__pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_validation, y__pred, pos_label=4)\n",
    "print('Precision: %f' % precision)\n",
    "\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_validation, y__pred, pos_label=4)\n",
    "print('Recall: %f' % recall)\n",
    "\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_validation, y__pred, pos_label=4)\n",
    "print('F1 score: %f' % f1)\n",
    "\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_validation, y__pred)\n",
    "print('ROC AUC: %f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p10pEaHOIu0e"
   },
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_validation, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TrYT8KbI7pP"
   },
   "outputs": [],
   "source": [
    "# confusion matrix nicely formatted\n",
    "plt.figure()\n",
    "plot_confusion_matrix(NB, X_validation, y_validation, cmap='Blues')  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gj3Ib2wHU73C"
   },
   "source": [
    "## Dolce and Gabbanna Addition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vj8SG0h-XmxP"
   },
   "outputs": [],
   "source": [
    "#This is importing dolce and gabanna data\n",
    "dg = pd.read_csv('/content/drive/My Drive/chopstickadd.csv', encoding = \"latin-1\", )\n",
    "dg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8kyRksPZKH5"
   },
   "source": [
    "#Clustering the D&G Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "klQ6nHdFZIcA"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "txt = lambda a: \"   \".join(a) \n",
    "\n",
    "#aggragte text based on the sentiments \n",
    "dt_all = dg.groupby(by=['predictions']).agg({'text': txt}).reset_index()\n",
    "dt_all\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S59Ak8lhaVH3"
   },
   "outputs": [],
   "source": [
    "collection = list(dg['text']) #the list of sample tweets\n",
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EfZFgyaca-m1"
   },
   "outputs": [],
   "source": [
    "# use the count vectorizer to get a document-word matrix (counts of tokens in each tweet) basically assigning value to words per tweet\n",
    "# pass in through the preprocessor (tweet cleaner) and tokenizer (seperating tweet into individual words)\n",
    "# max_features basically the number of features selected at random and without replacement at split\n",
    "model = CountVectorizer(preprocessor=preprocessor, tokenizer=tokenizer, max_features=2098)\n",
    "word_counters = model.fit_transform(collection)\n",
    "cloud = word_counters\n",
    "tokenizers = model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7xJWQ_P7c8hF"
   },
   "outputs": [],
   "source": [
    "#taking the tokenizer and formatting it into the array\n",
    "word_counters.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwGJ3AbidZVt"
   },
   "outputs": [],
   "source": [
    "tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITDrJijvddx_"
   },
   "source": [
    "##TF IDF-Vectorizer part for D&G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tc7FYlved0s_"
   },
   "outputs": [],
   "source": [
    "A = tfidf_transformer.fit_transform(word_counters) # we use the TF-IDF counts as the feature matrix into our models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qLtYe9q9fPDI"
   },
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "itPB92bSjT9J"
   },
   "outputs": [],
   "source": [
    "for penality in penalities:\n",
    "  what = LR.predict(A)\n",
    "  whatever = NB.predict(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_JKcmIP3wYU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqfPKjgGZh30"
   },
   "source": [
    "##World Cloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oeCv6hrKJScU"
   },
   "outputs": [],
   "source": [
    "# Look at Jackies code for word cloud\n",
    "import seaborn as sns; sns.set()\n",
    "import tweepy\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tsMNcikPkMz4"
   },
   "outputs": [],
   "source": [
    "#an example of word cloud with me just taking the tokenizers after being cleaned\n",
    "allWords = ' '.join(tokenizers)\n",
    "wordCloud  = WordCloud(width=500, height=300, random_state = 21, max_font_size =110).generate(allWords)\n",
    "\n",
    "plt.imshow(wordCloud, interpolation = \"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHzmbwg1SA50"
   },
   "outputs": [],
   "source": [
    "# Add More Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGZ4s2RIdkIj"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Actual Sentiment140.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
